使用坐标下降法
坐标下降法的依据：
![[Pasted image 20230405164636.png]]

在Lasso回归中，z是一个中间变量，表示当前变量（权重）w在其他变量保持不变的情况下的残差。具体来说，对于第j个特征变量，其残差为：

$$z_j = (y - Xw + w_j * x_j)$$

其中，$y$是样本标签，$X$是样本特征矩阵，$w$是当前所有变量（权重）的值组成的向量，$w_j$是第$j$个变量（权重）的值，$x_j$是第$j$个特征变量的取值。

在Lasso回归的坐标下降法中，我们依次对每个变量（权重）进行更新，而将其他变量保持不变。在更新第j个变量（权重）时，我们需要先计算出它的残差$z_j$，然后根据更新公式对其进行更新。具体来说，权重$w_j$的更新公式为：

$$w_j = sign(z_j) * max(|z_j|-λ, 0)$$

其中，$sign(z_j)$是$z_j$的符号函数，表示如果$z_j$大于0，则返回1，如果$z_j$小于0，则返回-1，如果$z_j$等于0，则返回0。$λ$是L1正则化系数，用于控制正则化的强度。

因此，在Lasso回归的坐标下降法中，$z$是一个中间变量，用于计算每个变量（权重）的更新值。

## 推导过程
[机器学习--坐标轴下降法_zipper112的博客-CSDN博客](https://blog.csdn.net/qq_36102055/article/details/117060248)

在Lasso回归中，我们的目标是最小化带有L1正则化项的损失函数：

$$L(w) = (1/2n) * ||y - Xw||^2 + λ * ||w||_1$$

其中，$y$是样本标签，$X$是样本特征矩阵，$w$是权重向量，$n$是样本数量，$λ$是L1正则化系数。

为了求解最优权重$w$，我们需要对损失函数$L(w)$进行优化。在坐标下降法中，我们依次对每个权重分量进行更新，而将其他分量保持不变。对于第$j$个权重分量$w_j$，我们将其它权重分量w_{-j}视为常数，可以将损失函数简化为：

$$L(w_j) = (1/2n) * ||y - Xw_{-j} - w_j * x_j||^2 + λ * ||w_{-j}||_1 + λ * |w_j|$$

其中，$w_{-j}$表示去除w_j分量后的权重向量，$x_j$是第$j$个特征向量。为了求解最优权重$w_j$，我们需要对损失函数$L(w_j)$关于$w_j$求导，并令导数为0。通过求导可以得到：

$$∂L(w_j)/∂w_j = - (1/n) * (y - Xw_{-j} - w_j * x_j) * x_j + λ * sign(w_j)$$

其中，$sign(w_j)$表示$w_j$的符号函数，即如果$w_j$大于0，则返回1，如果$w_j$小于0，则返回-1，如果$w_j$等于0，则返回0。令$∂L(w_j)/∂w_j=0$，